import streamlit as st
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import Ollama
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

import os
import tempfile

st.set_page_config(page_title="ðŸ“šðŸ§  Chat with your PDFs", layout="wide")
st.title("ðŸ“„ðŸ’¬ PDF Chatbot using Local LLM (Ollama)")

uploaded_files = st.file_uploader("Upload one or more PDFs", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_docs = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            loader = PyPDFLoader(tmp.name)
            all_docs.extend(loader.load())

    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    docs = splitter.split_documents(all_docs)

    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectordb = FAISS.from_documents(docs, embeddings)

    retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 4})

    llm = Ollama(model="llama3")

    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        verbose=False
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    st.subheader("ðŸ’¬ Chat with your document(s):")
    user_query = st.chat_input("Ask a question")

    if user_query:
        with st.spinner("Thinking..."):
            response = qa_chain.run(user_query)
            st.session_state.chat_history.append((user_query, response))

    # Display chat history
    for user_msg, bot_msg in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(user_msg)
        with st.chat_message("assistant"):
            st.markdown(bot_msg)
